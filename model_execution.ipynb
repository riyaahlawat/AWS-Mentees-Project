{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fdc06e-fa40-4d7a-8900-d579d6f8920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models # type: ignore\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f3f58-54f4-4adc-8180-4cf82283c9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths\n",
    "dataset_dir = \"processed_images\"  # Replace with your dataset path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c40678-f87e-4e42-b4d9-41c20145ba69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset from directories\n",
    "dataset = tf.keras.utils.image_dataset_from_directory(\n",
    "    dataset_dir,\n",
    "    image_size=(128, 128),\n",
    "    batch_size=32,\n",
    "    label_mode=\"int\",\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ec7f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Preprocess images\n",
    "# def preprocess_image(image, label):\n",
    "#     # Resize and normalize\n",
    "#     image = tf.image.resize(image, (128, 128))\n",
    "#     image = image / 255.0\n",
    "\n",
    "#     # Convert TensorFlow tensor to NumPy array for OpenCV\n",
    "#     image_np = image.numpy()  # Convert tensor to NumPy array\n",
    "#     image_np = (image_np * 255).astype(np.uint8)  # Scale to 0-255 for OpenCV\n",
    "#     image_np = cv2.cvtColor(image_np, cv2.COLOR_RGB2BGR)  # Convert to BGR format\n",
    "\n",
    "#     # Convert to HSV for skin detection\n",
    "#     hsv_image = cv2.cvtColor(image_np, cv2.COLOR_BGR2HSV)\n",
    "#     lower_skin = (0, 20, 70)  # Lower range for skin detection\n",
    "#     upper_skin = (20, 255, 255)  # Upper range for skin detection\n",
    "#     skin_mask = cv2.inRange(hsv_image, lower_skin, upper_skin)\n",
    "\n",
    "#     # Apply morphological operations\n",
    "#     kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "#     skin_mask = cv2.erode(skin_mask, kernel, iterations=2)\n",
    "#     skin_mask = cv2.dilate(skin_mask, kernel, iterations=2)\n",
    "\n",
    "#     # Apply mask to the image\n",
    "#     masked_image = cv2.bitwise_and(image_np, image_np, mask=skin_mask)\n",
    "\n",
    "#     # Detect edges using Canny\n",
    "#     edges = cv2.Canny(masked_image, 100, 200)\n",
    "\n",
    "#     # Convert processed image back to tensor\n",
    "#     edges = cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)  # Convert to RGB format\n",
    "#     edges_tensor = tf.image.convert_image_dtype(edges / 255.0)  # Normalize and convert to tensor\n",
    "\n",
    "#     # Return processed tensor and label\n",
    "#     return edges_tensor, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2083181",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rgb_to_grayscale(image, label):\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec73c62-57fa-4cdf-a9d6-853d431df7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare dataset\n",
    "# # Map preprocessing function to dataset\n",
    "# def preprocess_wrapper(image, label):\n",
    "#     image, label = tf.py_function(preprocess_image, [image, label], [tf.float32, tf.int64])\n",
    "#     print(label)\n",
    "#     image.set_shape((128, 128, 3))  # Ensure image has the correct shape\n",
    "#     label.set_shape([])  # Ensure label has the correct shape\n",
    "#     return image, label\n",
    "\n",
    "dataset = dataset.map(rgb_to_grayscale, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "\n",
    "validation_split = 0.2\n",
    "train_size = int((1 - validation_split) * len(dataset))\n",
    "train_dataset = dataset.take(train_size)\n",
    "val_dataset = dataset.skip(train_size)\n",
    "\n",
    "for images, labels in train_dataset.take(1):\n",
    "    print(f\"Images shape: {images.shape}\")\n",
    "    print(f\"Labels type: {type(labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f718644e-de46-4718-a5a1-678de965035f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "def build_model(input_shape=(128, 128, 1), num_classes=35):\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679818aa-b6dc-45ea-bf08-a5a5daceec75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = build_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_dataset, validation_data=val_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ca5dcf-ef42-4918-94d0-58cd5440b33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model to a file\n",
    "model.save(\"sign_language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fae285-ea40-4e27-99d4-6c58f065d7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "\n",
    "model = load_model(\"sign_language_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed2c320-fd06-424f-bf14-820a97ec13fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class_names = sorted(os.listdir(dataset_dir))\n",
    "class_names = class_names[1:]\n",
    "\n",
    "cap = cv2.VideoCapture(0)  # Open webcam\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Preprocess the frame\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "    resized_frame = cv2.resize(gray_frame, (128, 128)) \n",
    "    edges = cv2.Canny((resized_frame * 255).astype(np.uint8), threshold1=100, threshold2=200)  # Apply Canny edge detection\n",
    "    normalized_edges = edges / 255.0 # Resize to model input size\n",
    "    input_frame = tf.convert_to_tensor(normalized_edges, dtype=tf.float32)\n",
    "    input_frame = np.expand_dims(input_frame, axis=-1)  # Add channel dimension for grayscale\n",
    "    input_frame = np.expand_dims(input_frame, axis=0)       # Add batch dimension\n",
    "\n",
    "    # Predict the class\n",
    "    predictions = model.predict(input_frame)\n",
    "    predicted_class = class_names[np.argmax(predictions)]\n",
    "\n",
    "    # Display prediction on the frame\n",
    "    cv2.putText(frame, f\"Prediction: {predicted_class}\", (10, 30),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
    "    cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "    # Exit on 'q' key press\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f4949f5-2468-4749-b426-bbd24630a0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "image = cv2.imread(\"test_2.jpg\")\n",
    "ori = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0beac879-5974-4e65-b269-e599c95b5cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gray_frame = cv2.cvtColor(input_test, cv2.COLOR_BGR2GRAY)  # Convert to grayscale\n",
    "# _, binary_image = cv2.threshold(gray_frame, 100, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "# # Find contours in the binary image\n",
    "# contours, _ = cv2.findContours(binary_image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# # Create a blank mask\n",
    "# mask = np.zeros_like(gray_frame)\n",
    "\n",
    "# # Draw the largest contour (assuming it represents the hand) on the mask\n",
    "# # if contours:\n",
    "# #     largest_contour = max(contours, key=cv2.contourArea)\n",
    "# #     cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "#  # Refine contour selection\n",
    "# selected_contour = None\n",
    "# min_area = 100  # Minimum contour area threshold\n",
    "# max_area = 50000  # Maximum contour area threshold\n",
    "# image_center = np.array([gray_frame.shape[1] // 2, gray_frame.shape[0] // 2])\n",
    "\n",
    "# for contour in contours:\n",
    "#     # Filter by area\n",
    "#     area = cv2.contourArea(contour)\n",
    "#     if not (min_area < area < max_area):\n",
    "#         continue\n",
    "\n",
    "#     # Calculate bounding box aspect ratio\n",
    "#     x, y, w, h = cv2.boundingRect(contour)\n",
    "#     aspect_ratio = float(w) / h\n",
    "#     if not (0.5 < aspect_ratio < 2.0):  # Acceptable aspect ratio range\n",
    "#         continue\n",
    "\n",
    "#     # Calculate contour centroid distance from image center\n",
    "#     M = cv2.moments(contour)\n",
    "#     if M[\"m00\"] != 0:\n",
    "#         cx, cy = int(M[\"m10\"] / M[\"m00\"]), int(M[\"m01\"] / M[\"m00\"])\n",
    "#         distance_from_center = np.linalg.norm(image_center - np.array([cx, cy]))\n",
    "#         if selected_contour is None or distance_from_center < best_distance:\n",
    "#             selected_contour = contour\n",
    "#             best_distance = distance_from_center\n",
    "\n",
    "image = cv2.resize(image, (128, 128))\n",
    "hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "# Define the lower and upper range for skin color in HSV\n",
    "lower_skin = (0, 20, 70)   # Adjust as per the skin tone\n",
    "upper_skin = (20, 255, 255)\n",
    "\n",
    "# Create a mask for skin color\n",
    "skin_mask = cv2.inRange(hsv_image, lower_skin, upper_skin)\n",
    "\n",
    "# Apply morphological operations to clean up the mask\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (5, 5))\n",
    "skin_mask = cv2.erode(skin_mask, kernel, iterations=2)\n",
    "skin_mask = cv2.dilate(skin_mask, kernel, iterations=2)\n",
    "\n",
    "# Blur the mask for smoother edges\n",
    "skin_mask = cv2.GaussianBlur(skin_mask, (5, 5), 0)\n",
    "\n",
    "# Detect edges in the mask\n",
    "edges = cv2.Canny(skin_mask, 100, 200)\n",
    "\n",
    "# Find contours in the edge-detected mask\n",
    "contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "# Draw the largest contour on the original image\n",
    "if contours:\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    cv2.drawContours(image, [largest_contour], -1, (0, 255, 0), 2)\n",
    "\n",
    "# Plot the results\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.title(\"Original Image\")\n",
    "plt.imshow(cv2.cvtColor(ori, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.title(\"Skin Mask\")\n",
    "plt.imshow(skin_mask, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.title(\"Detected edges\")\n",
    "plt.imshow(cv2.cvtColor(edges, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# # Apply the mask to the original grayscale image\n",
    "# masked_image = cv2.bitwise_and(gray_frame, gray_frame, mask=mask)\n",
    "# cv2.imshow('image', masked_image) # Resize to model input size\n",
    "# cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c779685",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# edges = cv2.Canny((masked_image * 255).astype(np.uint8), threshold1=500, threshold2=600, L2gradient=True)  # Apply Canny edge detection\n",
    "# resized_frame = cv2.resize(edges, (128, 128))\n",
    "normalized_edges = edges / 255.0\n",
    "input_frame = tf.convert_to_tensor(normalized_edges, dtype=tf.float32)\n",
    "input_frame = np.expand_dims(input_frame, axis=-1)  # Add channel dimension for grayscale\n",
    "input_frame = np.expand_dims(input_frame, axis=0) \n",
    "pred = model.predict(input_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ceb5bb-2dc5-45f4-9853-667e94cd8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ind = 0\n",
    "maxi = 0\n",
    "for i in range(len(pred[0])):\n",
    "    if pred[0, i] > maxi:\n",
    "        maxi = pred[0, i]\n",
    "        ind = i\n",
    "print(ind+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a2f1c-f3da-493e-94e2-4525456748a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8d6b11-82b9-4930-8e02-13393c813d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d04fec3-5014-45c9-b8c1-e9995a77062f",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(input_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c002c2ff-08a2-48cf-ae58-b65f23cc2f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6635a178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
